{
  "public": {
    "netWorkError": "Network or backend service error. Ensure that the service is started successfully and reload the page.",
    "browserWarning": "Your browser may cause some functions to become invalid or unavailable. You are advised to use Chrome 65 or later.",
    "timeout": "Timeout. Try again.",
    "noData": "No data",
    "noSupport": "Not supported temporarily",
    "emptyData": "No data",
    "reset": "Reset",
    "tagFilterPlaceHolder": "Enter tag (regular expression supported)",
    "dataError": "The obtained data is abnormal.",
    "regIllegal": "Enter a correct search criterion.",
    "stayTuned": "Coming soon...",
    "select": "Select",
    "search": "Search",
    "enter": "Enter",
    "remark": "Remarks",
    "zhLanguage": "中",
    "enLanguage": "EN",
    "sure": "OK",
    "clear": "Clear",
    "cancel": "Cancel",
    "selectAll": "All",
    "deselectAll": "Clear",
    "dataLoading": "Loading data...",
    "notice": "Information",
    "caseMode": "Not case sensitive",
    "all": "All",
    "details": "Details",
    "delete": "Delete",
    "dark": "Dark Theme",
    "light": "Light Theme",
    "noOperatorData": "No data for non-heterogeneous networks",
    "noAICPUOperatorData": "There is no AICPU operator on this network. No data available.",
    "noStepStraceData": "Step trace analysis only supports single-graph scenarios in Graph mode, and does not support scenarios such as pynative, heterogeneous, and multi-subgraphs."
  },
  "unit": {
    "KiB": "KiB",
    "MiB": "MiB",
    "GiB": "GiB"
  },
  "symbols": {
    "leftbracket": "(",
    "rightbracket": ")",
    "point": "·",
    "slashes": "/",
    "colon": ":",
    "fullStop": ".",
    "comma": ","
  },
  "header": {
    "refreshData": "Refresh Data",
    "refreshingData": "Refreshing data...",
    "timeReload": "Auto Refresh",
    "timeSecond": "Seconds",
    "timeReloadScope": "The automatic refresh interval ranges from 3 to 300 seconds."
  },
  "summaryManage": {
    "summaryList": "Summary List",
    "currentFolder": "Current folder:",
    "sorting": "No.",
    "summaryPath": "Summary Path",
    "createTime": "Creation Time",
    "updateTime": "Update Time",
    "operation": "Operation",
    "viewDashboard": "Training Dashboard",
    "viewProfiler": "Profiling",
    "viewOfflineDebugger": "Offline Debugger",
    "modelTraceback": "Model Lineage",
    "dataTraceback": "Dataset Lineage",
    "comparePlate": "Comparison Dashboard",
    "scalarComparison": "Scalar Comparison",
    "lossComparison": "Loss Graph Comparison",
    "disableLossFunctionTip": "Failed to view loss function analysis because no log is available.",
    "disableProfilerTip": "Failed to view profiling because no profiler log is available.",
    "disableDashboardTip": "Failed to view training dashboard because no summary log or pb files are available.",
    "disableParameterTip": "Failed to view parameter details because no lineage log is available.",
    "disableOfflineDebugger": "Failed to view offline debugger because no debugger log is available.",
    "openNewTab": "Open Link in New Tab",
    "paramDetails": "Parameter Details",
    "trainingParamDetails": "Training Parameter Details",
    "tracebackAnalysis": "Lineage Analysis",
    "compareAnalysis": "Comparison Analysis",
    "guidTipFirst": "In the training script, add ",
    "guidTipSecond": "the function of collecting summary data ",
    "guidTipThird": "and save ",
    "guidTipForth": "data.",
    "scalarTipFirst": "scalar ",
    "histogramGuidTipFirst": "parameter distribution ",
    "tensorTipFirst": "tensor ",
    "graphTipFirst": "computational graph ",
    "graphTipSecond": "structure data.",
    "dataProcessTipFirst": "data processing process",
    "imageTipFirst": "specified image",
    "guidUrl": "https://www.mindspore.cn/mindinsight/docs/en/master/summary_record.html",
    "scalarUrl": "https://www.mindspore.cn/mindinsight/docs/en/master/dashboard.html#scalar-visualization",
    "histogramUrl": "https://www.mindspore.cn/mindinsight/docs/en/master/dashboard.html#parameter-distribution-visualization",
    "tensorUrl": "https://www.mindspore.cn/mindinsight/docs/en/master/dashboard.html#tensor-visualization",
    "graphUrl": "https://www.mindspore.cn/mindinsight/docs/en/master/dashboard.html#computational-graph-visualization",
    "dataProcessUrl": "https://www.mindspore.cn/mindinsight/docs/en/master/dashboard.html#dataset-graph-visualization",
    "imageUrl": "https://www.mindspore.cn/mindinsight/docs/en/master/dashboard.html#image-visualization",
    "sessionLimit": "The number of offline debugger sessions exceeds the upper limit.",
    "sessionLimitNum": "A maximum of two sessions are allowed.",
    "sessionLists": "Existing Sessions List",
    "deleteSessionConfirm": "The session will be deleted. Are you sure you want to continue?",
    "deleteSessionSuccess": "Session deleted.",
    "dumpPath": "Dump Path"
  },
  "modelTraceback": {
    "summaryPath": "Summary Path",
    "trainSetPath": "Training Set Path",
    "testSetPath": "Test Set Path",
    "trainingSampleNum": "Training Samples",
    "testSampleNum": "Testing Samples",
    "showAllData": "Show All",
    "showSelected": "Show Selected",
    "hideSelected": "Hide Selected",
    "network": "Network",
    "optimizer": "Optimizer",
    "lossFunc": "Loss Function",
    "learningRate": "Learning Rate",
    "modelSize": "Model Size",
    "dataProcess": "Data Processing",
    "noDataFound": "No data found.",
    "allHide": "All data is hidden.",
    "userDefined": "User-defined Data",
    "metric": "Metrics",
    "deviceNum": "Devices",
    "mixedItemMessage": "This parameter contains multiple types of data and cannot be filtered.",
    "notSupportSelected": "Filtering is not supported for this parameter type.",
    "displayColumn": "Displayed columns",
    "mustExist": "Mandatory",
    "remarkValidation": "Remarks can contain 1 to 128 characters, including letters, digits, underscores (_), hyphens (-), and periods (.).",
    "changeSuccess": "Modified successfully.",
    "metricLabel": "Metric",
    "userDefinedLabel": "User Defined",
    "hyperLabel": "Hyper",
    "otherLabel": "Other",
    "remarkTips": "Note: Once the service is terminated, remarks and tags will be cleared.",
    "optimizationObject": "Optimization Objective",
    "targetDistribution": "Optimization Objective Distribution",
    "parameterImportance": "Parameter Importance",
    "optimizationTitle": "Parameter and Optimization Objective",
    "viewBigImage": "Zoom In",
    "mustOptions": "Mandatory",
    "customOptions": "Custom",
    "targetTips": "Click a bar from the preceding chart to display a scatter chart of corresponding parameter and optimization objective.",
    "reasonCode": {
      "1": "The parameter contains non-numeric values.",
      "2": "The number of valid items of the parameter and optimization objective is less than or equal to 2. The importance cannot be calculated.",
      "3": "The importance is NaN."
    },
    "explan": "Note"
  },
  "dataTraceback": {
    "details": "Details",
    "key": "KEY",
    "value": "VALUE",
    "dataTraceTips": "The data involves combination.",
    "noDataFound": "No data found."
  },
  "trainingDashboard": {
    "trainingDashboardTitle": "Training Dashboard",
    "calculationChart": "Computational Graph",
    "dataMap": "Data Graph",
    "trainingScalar": "Training Scalar Information",
    "samplingData": "Data Sampling",
    "imagesampleSwitch": "Switch Tag",
    "invalidId": "Invalid job.",
    "summaryDirPath": "Summary path:",
    "loadingTip": "Loading...",
    "waitLoading": "waiting to be loaded",
    "switchTitle": "The Computational Graph and Data Graph modules do not support auto refresh.",
    "integrityInfo": "The summary data may be damaged. Ensure that the data you want to access is displayed properly."
  },
  "scalar": {
    "titleText": "Scalar",
    "tagSelectTitle": "Tag Selection",
    "xAxisTitle": "Horizontal axis",
    "smoothness": "Smoothness",
    "step": "Step",
    "selectAll": "All",
    "relativeTime": "Relative time",
    "absoluteTime": "Absolute time",
    "fullScreen": "Full Screen",
    "stepBack": "Rollback by Step",
    "openOrCloseSelection": "Enable/Disable Box Selection",
    "toggleYaxisScale": "Switch Y-axis Ratio",
    "charTipHeadName": "Name",
    "charTipTagName": "Tag",
    "charTipHeadValue": "Value",
    "charSmoothedValue": "Smoothness",
    "comparison": "Scalar Synthesis",
    "compareCancel": "Cancel Synthesis",
    "open": "More",
    "close": "Less",
    "invalidData": "Invalid data exists.",
    "restore": "Restore",
    "currentThreshold": "Current threshold",
    "deleteThreshold": "Delete Threshold",
    "setThreshold": "Set Threshold",
    "currentTag": "Current Tag",
    "filterCriteria": "Filter",
    "placeHolderThreshold": "Threshold",
    "or": "Or",
    "and": "And",
    "greaterThan": "Greater than",
    "lessThan": "Less than",
    "applyAllSelectTag": "Apply to Selected Tags",
    "placeHolderNumber": "Enter a number",
    "noSpace": "Do not enter spaces.",
    "sameCompare": "The comparison operator must be unique.",
    "unreasonable": "The logic is improper.",
    "info": "Information",
    "isDelete": "Are you sure you want to delete the current threshold?",
    "noLog": "There is no logarithm of 0 and negative numbers"
  },
  "images": {
    "titleText": "Image",
    "titleTip": "Only 10 images are displayed randomly.",
    "imageErrorTip": "The current image has been updated. View the image after data loading is complete.",
    "tagSelectTitle": "Tag Selection",
    "selectAll": "All",
    "open": "More",
    "close": "Less",
    "step": "Step:",
    "setBright": "Brightness",
    "setContrast": "Contrast"
  },
  "histogram": {
    "titleText": "Parameter Distribution",
    "xAxisTitle": "Vertical axis",
    "viewType": "Angle of View",
    "centerValue": "Center Value",
    "step": "Step",
    "relativeTime": "Relative Time",
    "absoluteTime": "Absolute Time",
    "overlay": "Front",
    "offset": "Top",
    "fullScreen": "Full Screen"
  },
  "dataMap": {
    "titleText": "Data Graph"
  },
  "tensors": {
    "mode": "Mode",
    "tableMode": "Table Mode",
    "chartMode": "Chart Mode",
    "titleText": "Tensor",
    "dimension": "Shape:",
    "tensorType": "Data type:",
    "viewTypeTitle": "View",
    "chartViewType": "Table",
    "histogramViewType": "Histogram",
    "tensorDashboardLimitErrorMsg": "The number of requested data records exceeds the upper limit 100,000. Click here to go to the tensor page and shard or query other dimensions."
  },
  "graph": {
    "titleText": "Computational Graph",
    "optimizeText": "Optimize the readability of the calculation diagram and reduce the complexity of the calculation diagram. Most of the gradient calculation logic and optimizer calculation logic in the diagram will be removed.",
    "downloadPic": "Download",
    "fitScreen": "Fit to Screen",
    "nodeInfo": "Node Information",
    "legend": "Legend",
    "nameSpace": "Namespace",
    "operatorNode": "Operator Node",
    "virtualNode": "Virtual Node",
    "constantNode": "Constant Node",
    "dynamicShapeNode": "Dynamic Shape Operator Node",
    "polymetric": "Aggregation Node",
    "dataFlowEdge": "Data Flow Edge",
    "controllDepEdge": "Control Dependency Edge",
    "name": "Name",
    "count": "Subnodes",
    "type": "Type",
    "attr": "Attribute",
    "inputs": "Input",
    "outputs": "Output",
    "outputs_i": "Outputs_i",
    "controlDependencies": "Control Edge",
    "searchLoading": "Locating nodes... Please wait. The locating speed depends on the number of nodes. A large number of nodes will slow down the speed.",
    "queryLoading": "Loading... Please wait.",
    "fullScreen": "Full Screen",
    "partScreen": "Part Screen",
    "tooManyNodes": "Too many nodes to open.",
    "openFail": "Failed to expand the node. Possible causes are as follows: 1. The machine performance is too poor to draw subnodes of the node. 2. The number of direct subnodes under the node exceeds 1500. 3. The connections between direct subnodes are too complex. ",
    "inputNodeName": "Enter node name",
    "guide": "User Guide",
    "guideTitle1": "Introduction 1 of 3: Main Functions",
    "guideTitle2": "Introduction 2 of 3: Node Types",
    "guideTitle3": "Introduction 3 of 3: Edges",
    "guideContent11": "1. In a computational graph display area, you can view a computational graph, zoom in or out a computational graph by scrolling the mouse wheel, and drag a computational graph.",
    "guideContent12": "2. A computational graph can be displayed in full screen or saved as an SVG file.",
    "guideContent13": "3. In the function area on the right, you can switch to view computational graphs of different files or search for nodes in a computational graph.",
    "guideContent14": "4. In the node information, you can click an input or output node to go to the selected node.",
    "guideContent2": "Node types of a computational graph include namespace node, operator node, virtual node,   aggregation node, and constant node. \"Default\" indicates forward propagation, and \"Gradients\" indicates backward propagation. ",
    "guideContent3": "Data edges and control edges exist in a computational graph. A data edge indicates the data input, and a control edge indicates the execution dependency between node.",
    "next": "Next",
    "finish": "Complete",
    "dataTooLarge": "Failed to open the graph because of too many nodes and edges.",
    "tooManyChain": "The direct subnode depth exceeds 70 and cannot be expanded.",
    "sidebarTip": "Select computational graph files to be viewed. A maximum of 10 files are supported. When the number of files exceeds 10, some files are not displayed. To view files that are not displayed, move them to other summary log path. "
  },
  "operator": {
    "currentCard": "Number of cards",
    "pie": "Pie",
    "bar": "Bar",
    "allOperator": "All",
    "classificationOperator": "Type",
    "card": " ",
    "searchByType": "Enter operator type",
    "searchByName": "Enter operator name",
    "operatorInfo": "Operator",
    "kernelInfo": "Kernel",
    "searchByCoreName": "Enter kernel name",
    "searchByCoreFullName": "Enter operator full name",
    "flops": "FLOPs",
    "flopsS": "FLOPS",
    "flopsUtilization": "FLOPS Usage:",
    "flopsUtilizationTitle": "FLOPS/Peak FLOPS",
    "scopeLevelFlops": "Scope-level FLOPs(M)"
  },
  "profiling": {
    "rankID": "Rank ID",
    "singleHost": "SingleCard",
    "cluster": "Cluster",
    "titleText": "Profiling - Single-host",
    "profilingDashboard": "Profiling Dashboard",
    "showAverage": "Average value",
    "iterationGapTime": "Step Interval",
    "fpBpTime": "Forward and Backward Propagation",
    "fpTime": "Forward Propagation",
    "tailTime": "Step Tail",
    "time": "Time",
    "operatorTimeConAnalysis": "Operator Time Consumption Analysis",
    "avgCost": "Average total consumed time:",
    "getCost": "Average data obtaining time:",
    "pushCost": "Average data push time:",
    "iterationGap": "Step Interval",
    "iterationTail": "Step Tail",
    "minddataTitle": "Data Preparation Details",
    "dataQueue": "Data Queues",
    "smartHelper": "Helper",
    "suggestions": "Suggestions",
    "common-profiler_tutorial": {
      "desc": "How Do I Use Profiler for Profiling?",
      "anchor": ["desc"],
      "url": [
        "https://www.mindspore.cn/mindinsight/docs/en/master/performance_profiling_ascend.html"
      ],
      "gpuUrl": [
        "https://www.mindspore.cn/mindinsight/docs/en/master/performance_profiling_gpu.html"
      ]
    },
    "step_trace-proposer_type_label": {
      "desc": "Step trace performance optimization"
    },
    "step_trace-iter_interval": {
      "desc": "After the praph mode and dataset sink mode are enabled, if the average step interval is greater than {n1} ms, the process from data processing to computational graph execution can be optimized.You can prepare performance analysis and optimization scripts based on the data."
    },
    "common-proposer_type_label": {
      "desc": "Profiling and optimization guide"
    },
    "minddata_pipeline-proposer_type_label": {
      "desc": "Data processing performance optimization"
    },
    "minddata_pipeline-general": {
      "desc": "The {n1} operator in the pipeline may have performance bottlenecks."
    },
    "minddata_cpu_utilization": {
      "desc": "The average CPU usage of the entire system is {n1}, which may affect the data processing performance."
    },
    "minddata_pipeline-dataset_op": {
      "desc": "For operator {n1}, you can try to increase or decrease the num_parallel_workers parameter."
    },
    "minddata_pipeline-generator_op": {
      "desc": "For operator {n1}, you can try to increase or decrease the num_parallel_workers parameter or optimize the training script. If the performance is not optimized, you can replace the operator with the MindRecordDataset operator."
    },
    "minddata_pipeline-map_op": {
      "desc": "For operator {n1}, you can try to increase or decrease the num_parallel_workers parameter. If the Python operator is used, you can optimize the training script."
    },
    "minddata_pipeline-batch_op": {
      "desc": "For operator {n1}, you can increase the prefetch_size value."
    },
    "minddata_device_queue_rate": {
      "empty_rate": "The ratio of empty queues on a host is {empty_rate}%, and the threshold is {empty_warning_threshold}%. The data processing stage can be optimized. You can adjust the script based on the data processing performance optimization suggestions.",
      "empty_warning_threshold": "The ratio of empty queues on a host is {empty_rate}%, and the threshold is {empty_warning_threshold}%. There are empty queues on a chip. The data transmission stage can be optimized. You are advised to commit issues in the MindSpore community."
    },
    "minddata-proposer_type_label": {
      "desc": "Step interval profiling"
    },
    "minddata_device_queue": {
      "desc": "The ratio of empty queues on a host is {n1}/{n2}, and the ratio of non empty queues is {n3}/{n4}."
    },
    "minddata_get_next_queue": {
      "desc": "The ratio of empty queues on a chip is {n1}/{n2}, and the ratio of non empty queues is {n3}/{n4}."
    },
    "device_queue_warning": {
      "desc": "You can optimize the script based on the data processing performance optimization suggestions."
    },
    "millisecond": "ms",
    "curCard": "Number of cards",
    "stepTrace": "Step Trace",
    "mindData": "Data Preparation",
    "timeLine": "Timeline",
    "rankOfOperator": "Operator Time Consumption Ranking",
    "stepTraceDetail": "Step Trace Details",
    "viewDetail": "Details",
    "stepNum": "Steps",
    "iterGapTimeLabel": "Time",
    "iterGapRateLabel": "Ratio",
    "fpBpTimeLabel": "Time",
    "fpTimeLabel": "Time",
    "fpBpRateLabel": "Ratio",
    "fpRateLabel": "Ratio",
    "tailTimeLabel": "Time",
    "tailRateLabel": "Ratio",
    "operatorDetail": "Operator Details",
    "times": "times",
    "queueStep": "Queue Step Distribution",
    "queueInfo": "Step Interval",
    "pipeline": "Data Processing",
    "pipelineTopTitle": "Average usage of queues between operators",
    "pipelineMiddleTitle": "Queue relationship between operators",
    "deviceQueueOp": "Data Transmission",
    "deviceQueueOpTip": "Forward and Backward Propagation",
    "deviceQueueOpFpTip": "Forward Propagation",
    "getNext": "Data Obtaining Operator",
    "connectorQuene": "Host Queues",
    "getData": "Data Obtaining",
    "opTotalTime": "Total operator execution time:",
    "streamNum": "Number of executed flows:",
    "opNum": "Number of operators:",
    "opTimes": "Total operator execution times:",
    "features": "Functions:",
    "iterationInfo": "The step trace displays the duration of each step from the start of the previous iteration to the end of the step. The main time is divided into three parts: step interval, forward and backward propagation, and step tail.(Note that this feature do not support heterogeneous training scene)",
    "iterationGapInfo": "Reads data from data queues. If this part takes a long time, you are advised to check the data processing for further analysis.",
    "fpbpTitle": "Forward and Backward Propagation",
    "fpbpInfo": "Executes the forward and backward operators on the network, which carry the main calculation work of a step. If this part takes a long time, you are advised to check the operator statistics or timeline for further analysis.",
    "iterativeTailingTitle": "Step Tail",
    "iterativeTailingInfo": "Performs parameter aggregation and update operations in multi-card scenarios. If the operations take a long time,you are advised to check the time consumed by all_reduce and the parallel status.",
    "statistics": "Statistics:",
    "totalTime": "Total consumed time:",
    "totalSteps": "Total steps:",
    "fpbpTimeRatio": "Ratio of time consumed by forward and backward propagation:",
    "fpTimeRatio": "Ratio of time consumed by forward propagation:",
    "iterationGapTimeRatio": "Ratio of time consumed by step interval:",
    "iterativeTailingTimeRatio": "Ratio of time consumed by step tail:",
    "dataProcess": "This shows the data processing. Data is stored in the host queue during data processing, and then stored in the data queue on a chip during data transmission. Finally, the forward and backward propagation get_next transmits the data to forward propagation.",
    "dataProcessInfo": "By determining the empty host and data queues, you can preliminarily determine the stage where the performance is abnormal.",
    "analysisOne": "1. If the step interval is long and some batches of the data queue on a chip are empty, the performance is abnormal during data processing and transmission. Otherwise, locate the internal problem of the forward and backward propagation get_next.",
    "analysisTwo": "2. If the performance is abnormal during data processing and transmission, check the host queue. If the host queue is empty at a high probability, the exception may occur during data transmission.",
    "higherAnalysis": "Note: You can perform advanced analysis based on the time consumed by operators.",
    "chipInfo": "Ratio of empty data queues on a chip:",
    "hostIsEmpty": "Ratio of empty queues on a host:",
    "hostIsFull": "Ratio of non empty queues on a host:",
    "operatorInfo": "Operator information of {msg1} and {msg2}",
    "workersNum": "Number of threads",
    "queueDeepChartTitle": "{msg} Depth Line Chart",
    "sampleInterval": "Sampling interval",
    "queueTip1": "Ratio of non empty queues:",
    "queueTip2": "Ratio of empty queues:",
    "totalCapacity": "Total capacity",
    "averageCapacity": "Average used capacity",
    "FPMessage": "FP start operator:",
    "BPMessage": "BP termination operator:",
    "approximateTime": "Total duration ≈ ",
    "stepInputTip": "Steps (an integer ranging from 1 to {max})",
    "stepInput": "1~{max}",
    "stageTip": "Please select stage",
    "inputError": "Input parameter error. Please enter a positive integer ranging from 1 to {max}",
    "defaultTip": "Average value (default)",
    "downloadTimeline": "Download",
    "timelineTips": {
      "title1": "The timeline function helps you analyze the training process and displays the following information:",
      "content11": "- Device(AICPU or AICORE) to which an operator is allocated for execution.",
      "content12": "- Flow tiling policy of MindSpore on the network.",
      "content13": "- Execution sequence and duration of an operator on a device.",
      "content14": "- Scope Name of Operator. For example, the full name of one operator is `Default/network/lenet5/Conv2D-op11`, the first scope of this operator is `Default`, the second scope is `network`. ",
      "title2": "How to view the timeline details?",
      "content21": {
        "part1": "Click ",
        "part2": "Download",
        "part3": " to save a file containing the timeline information to a local host."
      },
      "content22": "View the information using either Google plug-in (chrome://tracing) or Perfetto (https://ui.perfetto.dev/#!/viewer).",
      "content23": {
        "part1": "Select one of the preceding two tools, enter its address in an address box of a browser, and press ",
        "part2": "Enter",
        "part3": ". On the page that is displayed, click ",
        "part4": "Load",
        "part5": " in the upper left corner of the tracing tool or click ",
        "part6": "Open trace file",
        "part7": " in the left pane of the Perfetto tool."
      },
      "title3": "How to use the timeline?",
      "content31": "You can analyze whether the flow tiling policy is proper and whether the step interval and tail time are too long based on the timeline information.",
      "content32": "You can also locate an operator and view and analyze its execution time.",
      "title4": "The detailed explanation of timeline:",
      "content41": "Process Device ID: the timeline of operators executed on AICORE.",
      "content42": "Step: training steps.",
      "content43": "Scope Name: the scope of the operator shows the hierarchical structure of the operator in the computation graph.",
      "content44": "Stream #ID: operators executed on the stream.",
      "content45": "Process AICPU Op: the timeline of operators executed on AICPU.",
      "content46": "Process Communication Op: contains the timeline for the execution of communication operators.",
      "content47": "Process HOSTCPU Op: contains the timeline of operators executed on the HOSTCPU.",
      "content48": "Process Op Overlap Analyse: the timeline of all computation operators and communication operators merged,  it can be used to analyse the proportion of communication time.",
      "content49": "Merged Computation Op: it is the timeline after all computation operators are merged.",
      "content410": "Merged Communication Op: it is the timeline after all communication operators are merged.",
      "content411": "Pure Communication Op: pure communication time (the timeline of the communication operator after removing the overlap with the computation operator time).",
      "content412": "Free Time: there is no communication operator and calculation operator in the execution timeline."
    },
    "pynativeTimelineTips": {
      "content11": "- Device(Ascend or HOSTCPU) to which an operator is allocated for execution.",
      "content12": "- Execution sequence and duration of an operator on a device.",
      "content31": "You can locate an operator and view and analyze its execution time.",
      "content41": "Step: training steps.",
      "content42": "Ascend Op：operators executed on the Ascend.",
      "content43": "HOSTCPU Op：operators executed on the HOSTCPU."
    },
    "countUnit": "times",
    "unit": "ms/time",
    "gpuunit": "us/time",
    "chartTitle": "Average Time Consumption Ranking",
    "userUtilization": "User Usage",
    "sysUtilization": "System Usage",
    "ioUtilization": "I/O Usage",
    "idleUtilization": "Idle Usage",
    "avgUserUtilization": "Average User Usage:",
    "avgSysUtilization": "Average System Usage:",
    "avgIOUtilization": "Average I/O Usage:",
    "avgIdleUtilization": "Average Idle Usage:",
    "avgWaitingProcess": "Average Number of Waiting Threads:",
    "avgSwitchCount": "Average Number of Context Switches:",
    "logicCores": "Number of Logical CPU Cores:",
    "allOperators": "All Operators",
    "currentOperator": "Current Operator",
    "cpuStepInputTip": "Enter a positive integer ranging from 1 to {max}. The value of Start Step must be less than or equal to that of End Step.",
    "startStep": "Start Step:",
    "endStep": "End Step:",
    "filterStep": "Filter",
    "resetStep": "Reset",
    "cpuUtilization": "CPU Usage",
    "cpuStepTip": "The step value is a positive integer ranging from 1 to {max}.",
    "structuralCpuUtil": "CPU Usage of the Entire System",
    "processCpuUtil": "Process CPU Usage",
    "operatorCpuUtil": "Operator CPU Usage",
    "utilizationTitle": "Usage(%)",
    "executiveOverview": "Executive Overview",
    "trainingPerformance": "Training Performance",
    "resourceUtilization": "Resource Utilization",
    "strategyPerception": "Strategy Perception",
    "strategyReference": "Please refer to the detailed tutorial",
    "strategyTutorials": "Strategy Perception Tutorial",
    "strategyTutorialUrl": "https://www.mindspore.cn/mindinsight/docs/en/master/performance_profiling_of_cluster.html#strategy-perception",
    "rankSelector": "Stage Selector",
    "parallelStrategy": "Parallel Strategy",
    "hasStrategy": "Operator with Strategy",
    "redistribution": "Operator for Redistribution",
    "gradientAggregate": "Operator for Gradient Aggregation",
    "recomputeGraph": "Recompute Graph",
    "forwardGraph": "Feed-Forward Graph",
    "backwardGraph": "Back-Propagation Graph",
    "bipartiteExtractTips": "Select the graph to extract communication nodes from",
    "resetTips": "Click to reset the position",
    "bipartiteExtractSelector": "Graph Selector",
    "noneNodesTips": "No selected node",
    "trainingPipeline": "Training Pipeline",
    "specialNodeCnt": "Special Node Counts",
    "nodeAttribute": "Node Attributes",
    "updateButton": "Update",
    "memory": {
      "memoryDetailLink": "Memory Usage Information",
      "overView": "Memory Allocation OverView",
      "currentCard": "Number of Cards",
      "memoryAssign": "Number of Memory Allocations",
      "memoryRelease": "Number of Memory Releases",
      "totalMemory": "Total Available Memory",
      "staticMenory": "Static Memory",
      "memoryPeak": "Peak Memory Usage",
      "memoryGiBUnit": "GiB",
      "memoryMiBUnit": "MiB",
      "memoryKiBUnit": "KiB",
      "memoryByteUnit": "B",
      "usedMemory": "Memory Usage",
      "operatorMemoryAssign": "Operator Memory Allocation",
      "tensorName": "Tensor Name",
      "totalTensorMemoryAssign": "Tensor Size",
      "format": "Format",
      "tensorType": "Tensor Type",
      "dataType": "Data Type",
      "shapes": "Shape",
      "chartXaxisUnit": "Execution ID",
      "chartYaxisUnit": "Size(GiB)",
      "curOperaterId": "Current Operator Execution ID",
      "curOperator": "Current Operator",
      "curOperatorMemorySize": "Memory Occupied by Current Operator",
      "curMemorySize": "Total Occupied Usage",
      "memoryChanged": "Memory Change",
      "lifeCycle": "Lifecycle",
      "fpStart": "Forward",
      "bpEnd": "Backward"
    },
    "isHeterogeneous": "Heterogeneous training scenarios are not supported temporarily.",
    "scopeNameNum": "ScopeName Layer Counts: ",
    "flopsScopeTipOne": "Node movement: Drag the scope node to move it to the specified position.",
    "flopsScopeTipTwo": "Reset: Restore the graphics to the Initial state.",
    "flopsScopeTipThree": "Selected: Click to select a scope node, and its associated parent and child nodes will be highlighted for a long time, and click again to cancel the highlighting.",
    "operatorShapeStep": "Operator time-consuming (by iteration)",
    "opeatorFeatures": "The operator time-consuming (by iteration) shows the time-consuming of different types of operators under the specified step. You can select different types of operators to display through the filter box.",
    "gpuOpeatorFeatures": "The operator time consumption (by iteration) analysis component displays the execution time of each type of operator in different iterations, so as to quickly understand the detailed time consumption of each type of operator in each iteration.",
    "operatorSelectTitle": "Filter the specified operator type:",
    "timeConsume": "time consuming",
    "operatorShapeDetail": "Operator time-consuming details (by iteration)",
    "operatorShapeTip": "The operator time-consuming details (by iteration) display the operator time-consuming and shape information of the specified type. By default, 3 records are displayed. The operator shape information can be displayed by clicking the corresponding point on the smooth curve graph.",
    "operatorFilterTitle": "Filter the specified operator name:",
    "operatorShapeTitle": "Operator time-consuming details",
    "notSupportTitle": "Dynamic shape networks are not currently supported",
    "expertNoOpAdvice": "Expert system: AI CPU operators are well optimized",
    "expertOpAdvice": "Expert system: AI CPU operators need to be optimized",
    "adviceDetails": [
      "1.Modify the model code to avoid AI CPU operator operations.",
      "2.Fuse AI CPU opetators to reduce frequent switchover between AI CPU and AI Core operations.",
      "3.Change the model structure, for example, from INT64 to FP16.",
      "4.Optimize the performance of time-consuming AI CPU operators."
    ],
    "dataVersionTips": "The profiler data comes from MindSpore version {ms_version}, MindInsight version is {mi_version}, it is recommended that the two versions be consistent"
  },
  "profilingGPU": {
    "minddata_get_next_queue": {
      "desc": "The ratio of empty data queues is {n1}/{n2}, and the ratio of non empty queues is {n3}/{n4}."
    },
    "minddata_device_queue": {
      "desc": "The ratio of empty queues on a host is {n1}/{n2}, and the ratio of non empty queues is {n3}/{n4}."
    },
    "dataProcess": "This shows the data processing. Data is stored in the host queue during data processing, and then stored in the data queue during data transmission. Finally, the forward and backward propagation get_next transmits the data to forward propagation.",
    "dataProcessInfo": "By determining the empty host and data queues, you can preliminarily determine the stage where the performance is abnormal.",
    "analysisOne": "1. If the step interval is long and some batches of the data queue are empty, the performance is abnormal during data processing and transmission. Otherwise, locate the internal problem of the forward and backward propagation get_next.",
    "analysisTwo": "2. If the performance is abnormal during data processing and transmission, check the host queue. If the host queue is empty at a high probability, the exception may occur during data transmission.",
    "chipInfo": "Ratio of empty data queues:"
  },
  "profilingCluster": {
    "clusterStepView": "Cluster Step Trace Overview",
    "clusterCommView": "Cluster Communication Overview",
    "clusterView": "Cluster Overview",
    "parallelStrategyView": "Parallel Strategy View",
    "mareyView": "Marey View",
    "timeOverview": "Time Overview",
    "namescope": "Namescope",
    "hiddenEdge": "Hidden Edge",
    "specialTypeOperator": "Operators with special type:",
    "operator": "Operator",
    "parameter": "Parameter",
    "fpbpTitle": "Forward and Backward Propagation",
    "FLOPs": "FLOPs",
    "ratio": "Ratio",
    "p2pcomm": "Point-to-point Communication",
    "averageCondition": "Average condition in a stage",
    "openBrush": "Whether to open brush",
    "showHiddenEdges": "Whether to show hidden edges",
    "collectiveCommunication": "Collective Communication",
    "sendOperator": "Send",
    "receiveOperator": "Receive",
    "parallelShardOperator": "Parallel Shard",
    "redistributionOperator": "Redistribution",
    "gradientAggOperator": "Gradient Aggregation",
    "memory": "Memory",
    "nodelinkGraph": "Node-link graph:",
    "totalcomm": "The total communication cost",
    "totalTrainingTimeMs": "Total training time(ms)",
    "commProportion": "communication time/(communication time+waiting time)",
    "matrixDescription": "Matrix:",
    "commTime": "Communication time",
    "traffic": "Traffic",
    "bandwidth": "Bandwidth",
    "totalTrainingTime": "Total training time of each device",
    "averageCommTime": "Average communication time of all devices",
    "averageWaitingTime": "Average waiting time of all devices",
    "commWaitTime": "Communication time/Waiting time(ms)",
    "rankID": "Rank ID",
    "host": "Host",
    "peakMem": "Peak Memory Usage",
    "capaCity": "Maximum Available Memory",
    "maximumPeakRatio": "Peak Memory Usage Ratio",
    "unit": "KIB",
    "timeTitle": "time(ms)",
    "stepChartTitle": "Cluster Step Trace",
    "commChartTitle": "Cluster Communication",
    "memoryHeatMapTitle": "Memory Heatmap Analysis",
    "flopsHeatMapTitle": "FLOPs Heatmap Analysis",
    "opName": "Operator Name",
    "waitCost": "Waiting Duration",
    "waitCostExplanation": "Also known as synchronization time. Before the two devices communicate with each other, ensure that synchronization has been performed. The waiting time is the total time consumed by all the Notify Wait operators minus the time consumed by the Notify Wait operator during the RDMA link communication.",
    "commCost": "Communication Duration",
    "commCostExplanation": "Indicates the communication time of communication operators. If the communication takes a long time, a link may be faulty. You can locate the specific link based on the link bandwidth. The communication time is the total time consumed by communication operators of the SDMA link(intra-server communication) and RDMA link(inter-server communication).",
    "commPerformance": "Communication Performance",
    "linkInfo": "Link Information",
    "linkInfoExplanation": "A device is used as source or destination device to display the link information. The link information includes the communication time, traffic, bandwidth(traffic divided by communication time), and link type.",
    "commSize": "Traffic",
    "linkType": "Link Type",
    "linkTypeExplanation": "Link types include the SDMA link(intra-server communication) and RDMA link(inter-server communication)",
    "linkRange": "Link Relationship",
    "bandWidth": "Bandwidth",
    "startID": "Source ID",
    "endID": "Destination ID",
    "deviceId": "Device",
    "granuLarity": "GranuLarity",
    "mainTipTitle": "Function description:",
    "mainTipPartOne": "This function provides users with memory usage overview in the cluster scenario in the form of heatmap. It reflects the proportion of the peak memory of each training device in the cluster to the maximum available memory of the training device.",
    "mainTipPartTwo": "Peak memory usage = Peak memory usage/Maximum available memory of the training device. The maximum peak memory usage is 1.",
    "mainTipPartThree": "Granularity: indicates the peak memory usage of different devices, that is, the granularity of the corresponding color value.",
    "mainTipPartFour": "You can also view the cluster overview of the training on the GUI, for example, the number of training devices used. You can click a training device to go to its memory details page.",
    "flopsTipPartOne": "This function provides the number of floating-point operations (FLOPS) data of each device in the cluster scenario in the form of heatmap.",
    "flopsTipPartTwo": "The heatmap reflects the relative size of FLOPs between devices. The color of the rectangle block corresponding to each device indicates the ratio of the current device FLOPs to the maximum FLOPs of all devices.",
    "flopsTipPartThree": "Granularity: indicates the granularity of the color values corresponding to the FLOPs data of different devices.",
    "flopsTipPartFour": "You can also view the cluster overview of the training on the GUI, for example, the number of devices used. You can click a device to go to the operator details page of the device.",
    "communicationAloneTime": "Communication time",
    "computationTime": "Computation time",
    "receiveAloneTime": "Communication time (only include the Receive operator)",
    "stageTime": "Stage time",
    "collectiveCommunicationAlone": "Communication time (not including the Receive operator)",
    "iterationGapTimeTip": "Mainly responsible for reading data from the data queue. If this part takes a long time, it is recommended to go to the data processing part for further analysis.",
    "fpBpTimeTip": "Execute the forward operator and Backward operator in the network, and carry the main calculation work of a step. If this part takes a long time, it is recommended to go to the operator statistics or timeline for further analysis.",
    "tailTimeTip": "Mainly perform parameter aggregation and parameter update operations in multi-card scenarios. If this part takes a long time, it is recommended to check the time-consuming and parallel situation of all_reduce.",
    "stageTimeTip": "The time-consuming duration of each stage. This value is the duration of the step minus the duration of the receive communication operator in the step. Through this indicator, you can see which stage takes the longest time.",
    "communicationAloneTimeTip": "the time period when only the communication operator is executed, and the calculation operator is not executed. If this part takes a long time, it means that the communication time-consuming has a greater impact on performance.",
    "receiveAloneTimeTip": "only the point-to-point (receive) communication operator is executed, and the calculation operator does not execute the time period. This time period reflects the asynchronous situation between the parallel stages of the Pipeline.",
    "computationTimeTip": "The total execution time of AICore operator, used to judge whether there is a slow card. The longer the time, the slower the execution speed of the corresponding card.",
    "collectiveCommunicationAloneTip": "Only the time period during which other communication operators except the receive communication operator are executed, and the calculation operator does not execute. The greater the proportion of this time period, the need to consider whether the segmentation strategy of the operators in the stage can be adjusted to reduce the time-consuming duration of this time period.",
    "flopsRateLabel": "the ratio of the current device FLOPs to the maximum FLOPs of all devices",
    "step_interval": "The step interval of the device {rank_id} is {val} ms, which is {percent}% higher than the average value of each device. This may affect the overall performance. Pay attention to the data preparation stage on the single node page of the device.",
    "flops_per_second": "The FLOPS value of the device {rank_id} is {val} G/s, which is {percent}% lower than the average value of each device. This may affect the overall performance. Pay attention to this device.",
    "cluster_link": "The bandwidth of the communication link ({link_type}) from device {src_rank} to device {des_rank} is {val} KB/s, which is {percent}% lower than the average bandwidth of the {link_type} link. This may affect the overall performance. Pay attention to this link.",
    "parallel_strategy": {
      "data_parallel_communication_rate": "From the step tail and step trace, it can be concluded that the ratio of the model communication duration is {val}%, which exceeds the empirical threshold {threshold}%. You can set the all_reduce_fusion_config parameter by referring to the MindSpore parallel distributed tutorial to adjust the AllReduce fusion and shard strategy of a gradient to reduce the communication duration.",
      "model_parallel_communication_rate": "The ratio of the model communication duration is {val}%, which exceeds the empirical threshold {threshold}%. You can try to analyze and optimize the operator segmentation strategy through the 'policy awareness' page under the cluster to reduce the communication time.",
      "pipeline_parallel_between_stage": "The ratio of the inter-stage communication (only for the Receive operator) duration is {val}%, which exceeds the empirical threshold {threshold}%. You can analyze the cause of the long time consumed by the Receive operator based on the timeline.",
      "pipeline_parallel_within_stage": "The ratio of the communication duration (except the Receive operator) in stage {stage} is {val}%, which exceeds the empirical threshold {threshold}%. The ratio of the communication duration (except the Receive operator) in stage {stage} is {val}%, which exceeds the empirical threshold {threshold}%.",
      "pipeline_parallel_flops": "The average computation amount of the stage{stage} card is {val}M, which is {percent}% higher than the average value of each stage. You can try to optimize the stage segmentation strategy to balance the computation amount of each stage."
    },
    "step_interval_title": "Step Interval Profiling",
    "flops_per_second_title": "Device Computing Profiling",
    "cluster_link_title": "Inter-Device Link Bandwidth Profiling",
    "parallel_strategy_title": "Communication Operator Sharding Reasonability Analysis",
    "clusterPerformanceTest": "How do I use Profiler for cluster performance debugging?",
    "clusterGuideUrl": "https://www.mindspore.cn/mindinsight/docs/en/master/performance_profiling_of_cluster.html",
    "clusterGPUGuideUrl": "https://www.mindspore.cn/mindinsight/docs/en/master/performance_profiling_of_cluster.html"
  },
  "components": {
    "summaryTitle": "Training Selection",
    "tagSelectTitle": "Tag Selection",
    "selectAll": "All",
    "tagFilterPlaceHolder": "Enter tag (regular expression supported)",
    "trainFilterPlaceHolder": "Enter training (regular expression supported)",
    "open": "More",
    "close": "Less",
    "gridIncorrectDataError": "A maximum of two-dimensionalarrays can be displayed.",
    "gridAccuracy": "Decimal places are reserved.",
    "inCorrectInput": "Invalid input.",
    "gridTableNoData": "No data in the table.",
    "value": "Value",
    "dimsFilterInputTitle": "Dimension Selection",
    "dimsFilterInputTip": "The dimension value can be a specific index (consistent with the Python index meaning and supporting negative signs) or a colon (:) that indicates all values of the current dimension.The number of Tensor columns does not exceed 1,000, and the total number does not exceed 100,000.",
    "category": "Type",
    "scientificCounting": "Scientific notation",
    "accuracyTips": "If a value is not completely displayed, drag a border of the table header to resize.",
    "startText": "Start",
    "endText": "End",
    "optimize": "optimize"
  },
  "debugger": {
    "debugger": "Debugger",
    "nodeTypes": "Node Types",
    "nodeList": "Node List",
    "watchList": "Watchpoint list",
    "watchPoint": "Watch Point",
    "continue": "CONTINUE",
    "pause": "PAUSE",
    "terminate": "TERMINATE",
    "selectCondition": "Select a condition",
    "inputStep": "Enter a step value",
    "inputTip": "A positive integer less than or equal to {total_step_num}",
    "curHitNode": "Watchpoints found",
    "backstageStatus": "The backend running status is ",
    "view": "View",
    "deleteWatchpointConfirm": "Are you sure you want to delete the watchpoint?",
    "clearWatchpointConfirm": "All watchpoints will be deleted. Are you sure you want to continue? ",
    "ternimateConfirm": "Are you sure you want to end the status?",
    "createWP": "Create Watchpoint",
    "successCreateWP": "The watchpoint is created.",
    "successDeleteWP": "The watchpoint is deleted.",
    "pendingTipsOff": "Waiting for data loading...",
    "pendingTips": "Waiting for training connection...",
    "nextNodeTip": "This is the last node.",
    "previousNodeTip": "This is the first node.",
    "serviceError": "Failed to connect to the backend service. Check and refresh the page.",
    "debuggerError": "Failed to connect to the backend service. Check whether the debugger service is properly started.",
    "tolerance": "Tolerance",
    "curValue": "Current Value",
    "compareToPre": "Compare with Previous Step",
    "stepTip": "The value 0 indicates the initial training state.",
    "stepTipOffline": "(Steps are numbered from 1, Note that the iteration field in the dump configuration file is numbered from 0. The two concepts are different, and the difference in value is one.)",
    "toSummeryList": "Go to Summary List",
    "clientIp": "Client IP",
    "deviceId": "Device ID",
    "currentStep": "Step",
    "step": "Step",
    "currentNode": "Current Node",
    "previousNode": "Previous Node",
    "nextNode": "Next Node",
    "tensorMsg": "Tensor Value Overview",
    "dType": "DType",
    "shape": "Shape",
    "value": "Value",
    "largeDataTip": "The requested data exceeds the upper limit 100,000. Shard or query other dimensions.",
    "continueTo": "Continue to",
    "inf": "INF:",
    "negativeInf": "-INF:",
    "max": "MAX:",
    "min": "MIN:",
    "mean": "MEAN:",
    "nan": "NAN:",
    "zero": "0:",
    "positiveNum": "Positive number:",
    "negativeNum": "Negative number:",
    "true": "TRUE:",
    "false": "FALSE:",
    "all": "All",
    "tensorTip": "tensor",
    "recheck": "Recheck (only for watchpoints with tensor values)",
    "clearWatchpoint": "Clear Watchpoint",
    "nodeType": {
      "all": "All",
      "weight": "Weight",
      "gradient": "Gradient",
      "activation": "Activation"
    },
    "recheckSuccess": "Rechecked.",
    "curStatisticsLabel": "Current Step:",
    "preStatisticsLabel": "Previous Step:",
    "diffStatisticsLabel": "Comparison Result:",
    "graphName": "Graph Name",
    "tensorDiagram": "Tensor Relationship Diagram",
    "selectDetail": "Select a tensor and double-click it to view details.",
    "operator": "Operator",
    "optimizationOrientation": "Optimization Guide",
    "tuningAdvice": "Optimization Suggestions",
    "setValue": "Preset Value",
    "actualValue": "Actual Value",
    "noWatchPoint": "No watchpoints found.",
    "tensorTuningRule": {
      "operator_real_data_validation": "Real data validation using single operator",
      "loss_overflow": "Loss overflow (NAN,INF)",
      "weight_condition_collection": "Weight check",
      "weight_initialization": "Initial weight value",
      "weight_overflow": "Weight overflow",
      "weight_too_large": "Weight above threshold",
      "weight_too_small": "Weight below threshold",
      "weight_not_changed": "Unchanged weight",
      "weight_change_too_large": "Weight change above threshold",
      "weight_change_too_small": "Weight change below threshold",
      "gradient_condition_collection": "Gradient check",
      "gradient_vanishing": "Gradient disappearance",
      "gradient_too_large": "Gradient above threshold",
      "gradient_exploding": "Gradient explosion",
      "activation_condition_collection": "Activation value check",
      "activation_range": "Activation value range",
      "tensor_condition_collection": "Tensor check",
      "tensor_overflow": "Tensor overflow",
      "operator_overflow": "Operator overflow",
      "tensor_initialization": "Initial tensor value",
      "tensor_too_large": "Tensor above threshold",
      "tensor_too_small": "Tensor below threshold",
      "tensor_range": "Tensor value range",
      "tensor_all_zero": "Whether tensor values are all 0",
      "tensor_change_too_large": "Tensor change above threshold",
      "tensor_change_too_small": "Tensor change below threshold",
      "tensor_not_changed": "Unchanged tensor",
      "zero_percentage_ge": "Percentage of 0 values ≥",
      "abs_mean_gt": "Average of the absolute value >",
      "abs_mean_lt": "Average of the absolute value <",
      "range_start_inclusive": "Lower limit of the range (inclusive)",
      "range_end_inclusive": "Upper limit of the range (inclusive)",
      "range_percentage_lt": "Percentage of the value in the range <",
      "range_percentage_gt": "Percentage of the value in the range >",
      "rtol": "Relative tolerance",
      "abs_mean_update_ratio_gt": "Ratio of mean update >",
      "abs_mean_update_ratio_lt": "Ratio of mean update <",
      "param": "Threshold",
      "max_min_lt": "MAX-MIN <",
      "max_min_gt": "MAX-MIN >"
    },
    "tensorTuningAdvice": {
      "operator_real_data_validation": [
        "Real data validation using single operator",
        "The operator may be faulty. You can perform the following operations to locate the fault:",
        ["1.Check whether the operator implementation is correct."]
      ],
      "loss_overflow": [
        "Loss overflow (NAN,INF)",
        "Loss overflow occurs. This may be an anomaly. You can perform the following operations to locate the fault:",
        [
          "1.Check whether a tensor overflow occurs on a network. Find the first overflow tensor for further analysis."
        ]
      ],
      "weight_initialization": [
        "Initial weight value",
        "The initial weight value may be incorrect. This may be an anomaly. You can perform the following operations to locate the fault:",
        [
          "1.Check whether the weight initialization algorithm in the script is correct."
        ]
      ],
      "weight_overflow": [
        "Weight overflow",
        "Weight value overflow occurs. This may be an anomaly. You can perform the following operations to locate the fault:",
        [
          "1.Check whether the learning rate is too high.",
          "2.Check whether the gradient is too large.",
          "3.Check whether the optimizer algorithm is correct."
        ]
      ],
      "weight_too_large": [
        "Weight above threshold",
        "The weight value is greater than the threshold. This may be an anomaly. You can perform the following operations to locate the fault:",
        [
          "1.Check whether the learning rate is correct.",
          "2.Check whether the gradient is correct.",
          "3.Check whether the optimizer algorithm is correct.",
          "4.Check whether the weight before the update is too large."
        ]
      ],
      "weight_too_small": [
        "Weight below threshold",
        "The weight value is less than the threshold. This may be an anomaly. You can perform the following operations to locate the fault:",
        [
          "1.Check whether the learning rate is correct.",
          "2.Check whether the gradient is correct.",
          "3.Check whether the optimizer algorithm is correct.",
          "4.Check whether the weight before the update is too small."
        ]
      ],
      "gradient_vanishing": [
        "Gradient disappearance",
        "Gradient disappears. This may be an anomaly. You can perform the following operations to locate the fault:",
        ["1.Check whether the input tensor of the operator is normal."]
      ],
      "gradient_too_large": [
        "Gradient above threshold",
        "The gradient value is greater than the threshold. This may be an anomaly. You can perform the following operations to locate the fault:",
        ["1.Check whether the input tensor of the operator is normal."]
      ],
      "gradient_exploding": [
        "Gradient explosion",
        "Gradient value overflows. This may be an anomaly. You can perform the following operations to locate the fault:",
        ["1.Check whether the input tensor of the operator is normal."]
      ],
      "activation_range": [
        "Activation value range",
        "The activation value range is not within the specified range. This may be an anomaly. You can perform the following operations to locate the fault:",
        ["1.Check whether the input tensor of the operator is normal."]
      ],
      "tensor_overflow": [
        "Tensor overflow",
        "Tensor overflows. This may be an anomaly. You can perform the following operations to locate the fault:",
        ["1.Check whether the input tensor of the operator is normal."]
      ],
      "operator_overflow": [
        "Operator overflow",
        "Overflow occurs during operator computation. This may be an anomaly. You can perform the following operations to locate the fault:",
        ["1.Check whether the input tensor of the operator is normal."]
      ],
      "tensor_too_large": [
        "Tensor above threshold",
        "The tensor is greater than the threshold. This may be an anomaly. You can perform the following operations to locate the fault:",
        ["1.Check whether the input tensor of the operator is normal."]
      ],
      "tensor_too_small": [
        "Tensor below threshold",
        "The tensor is less than the threshold. This may be an anomaly. You can perform the following operations to locate the fault:",
        ["1.Check whether the input tensor of the operator is normal."]
      ],
      "tensor_range": [
        "Tensor value range",
        "The tensor value range is not within the configured range. This may be an anomaly. You can perform the following operations to locate the fault:",
        ["1.Check whether the input tensor of the operator is normal."]
      ],
      "tensor_all_zero": [
        "Whether tensor values are all 0",
        "There are too many 0 values in a tensor. This may be an anomaly. You can perform the following operations to locate the fault:",
        ["1.Check whether the input tensor of the operator is normal."]
      ],
      "weight_not_changed": [
        "Unchanged weight",
        "The weight is not updated. This may be an anomaly. You can perform the following operations to locate the fault:",
        [
          "1.Check whether the learning rate is too low.",
          "2.Check whether the gradient is too small.",
          "3.Check whether the optimizer algorithm is correct.",
          "4.Check whether the weight is fixed."
        ]
      ],
      "weight_change_too_large": [
        "Weight change above threshold",
        "The weight change is greater than the threshold. This may be an anomaly. You can perform the following operations to locate the fault:",
        [
          "1.Check whether the learning rate is correct.",
          "2.Check whether the gradient is correct.",
          "3.Check whether the optimizer algorithm is correct."
        ]
      ],
      "weight_change_too_small": [
        "Weight change below threshold",
        "The weight change is less than the threshold. This may be an anomaly. You can perform the following operations to locate the fault:",
        [
          "1.Check whether the learning rate is correct.",
          "2.Check whether the gradient is correct.",
          "3.Check whether the optimizer algorithm is correct."
        ]
      ]
    },
    "noAdvice": "No suggestions available",
    "curStep": "Current Step",
    "preStep": "Previous Step",
    "compareResult": "Comparison Result",
    "recommendTip": "Whether to check for common anomalies?",
    "recommendDetail": "Check for common anomalies such as all tensors, disappearing gradients, and excessive weight updates.",
    "use": "Yes",
    "notUse": "No",
    "outdateTip": "When a watchpoint list or the current step is modified, the result may be outdated. Check again or perform subsequent step training. ",
    "versionConflictTip": "MindSpore and MindInsight versions do not match. MindSpore version: {msv}; MindInsight version: {miv}",
    "checkTips": {
      "nan": "A tensor contains NaN, ",
      "inf": "A tensor contains +/-INF, ",
      "no_prev_tensor": "The previous step value cannot be found, ",
      "out_of_mem": "The tensor size exceeds the memory limit, ",
      "no_history": "Graph history file is not available, ",
      "cannotCheck": "check fails."
    },
    "stateTips": {
      "waiting": "Ready",
      "running": "Running",
      "sending": "Waiting for command execution",
      "pending": "Waiting for backend connection"
    },
    "stateMsg": {
      "running": "The training is running.",
      "sending": "Wait for the command to be executed."
    },
    "paramErrorMsg": {
      "errorType": "Enter a number",
      "percentError": "The percentage value cannot be less than 0 or greater than 100.",
      "rangeError": "The lower limit cannot be greater than the upper limit.",
      "nonnegative": "The parameter value cannot be less than 0.",
      "allPositive": "he parameter value must be greater than 0.",
      "watchOverflow": "The asynchronous full overflow watching function must be enabled before the training starts."
    },
    "paramValueTip": "Preset Value: {value}",
    "logicCard": "Logic card",
    "inpStepTip": "Step：0~{total_step_num}",
    "stackList": "Stack List",
    "searchConditions": "Search Conditions",
    "nodeName": "Node Name",
    "stackInfo": "Stack Info",
    "inputStack": "Enter stack information",
    "search": "Search",
    "downloadTip": "The file is being loaded. The file size is about {fileSize}. Please wait.",
    "noOfflineGraphData": "Failed to load the computational graph. This may be due to the missing or damaged graphs file in the offline dump data in the summary directory. Please try to dump the data again.",
    "largeDataLoading": "The tensor data is large and loading...",
    "overSize": "The requested tensor is too large. The total value of the value exceeds 1GiB and cannot be displayed.",
    "noOfflineGraphName": "The graph name is missing.",
    "state": "State",
    "stateInfo": {
      "waiting": "Ready: Waiting for user operations.",
      "running": "Running: The training is in progress or watchpoints are being checked. It may take a long time if the model or data volume is too large. Please wait.",
      "sending": "Waiting for command execution: A new command is waiting for the current command to be finished.",
      "pending": "Waiting for backend connection: Waiting for a new training connection or the debugger environment is being initialized."
    },
    "back": "Back",
    "graphExecutionHistory": "Graph Execution History",
    "graphExecutionStep": "Graph Execution Rounds",
    "hasData": "Containing Data",
    "forward": "Forward",
    "yes": "Yes",
    "no": "No",
    "hasDataTip": "Tensor data is saved in this round.",
    "currentStepTip": "Indicates the current graph execution round",
    "noDistinguish": "All",
    "newGraphName": "New graph received: {graphNames}. (Note: There is no monitoring point on the new graph, please set it yourself if necessary.)",
    "noExexutionGraph": "The graph execution history file in the execution_order directory is missing, and the graph execution history cannot be viewed.",
    "graphExecutionHistoryTip": "Graph execution history file: saves the historical round information of the graph execution.",
    "noExecutionHistoryFile": "Graph history file is not available",
    "stackTip": "Some operators are generated by the framework. These operators may be associated with the code of the framework itself, or there is no code to associate, which is normal. These operators are for example TupleGetItem, Depend, UpdateState, etc.",
    "createWpTip": {
      "explain": "Watchpoints are used to set detection rules for a group of nodes.",
      "example": "For example, create a watchpoint for 'checking too large tensor' and set the check parameter to max > 100. After performing the check, you can find the tensor with the 'maximum value greater than 100'."
    },
    "graphNameExplain": "Different from the graph names in the node list, only the list of graph names executed during training is shown here.",
    "graphExecutionCountTip": "Graph execution round: the number of the exxcution rounds is calculated formula:\nround_id = sink_num * sink_size + loop_id\nsink_num: the cumulative number of times all graphs are issued\nsink_size: the number of cycles executed each time the current graph is issued \nloop_id: the sequence number of the loop\n such as: Suppose there is a training which has sunk 4 graphs so far, and now it will execute graph_0 6 times. This Graph will be sunk twice and be executed 3 times for each sink round. \nIn this case, the graph_0 will generate 6 round IDs, and the sink_size = 3. \nThe round IDs are:\n12 = 4 * 3 + 0\n13 = 4 * 3 + 1\n14 = 4 * 3 + 2\n15 = 5 * 3 + 0\n16 = 5 * 3 + 1\n17 = 5 * 3 + 2",
    "nodeIsLargeTip": "The graph node data saved in this training exceeds {maxGraphNodeSize}. Please reduce the number of graph files to re-enter or use the offline debugger API for data analysis.",
    "dataVersionTips": "The dump data comes from MindSpore version {ms_version}, MindInsight version is {mi_version}, it is recommended that the two versions be consistent"
  },
  "explain": {
    "explain": "Model Explanation",
    "explainSummary": "Explanation List",
    "explainSummaryCurrentFolder": "Root path of the explanation log:",
    "summaryPath": "Explanation Log Path",
    "title": "Saliency Map Visualization",
    "conterfactualInterpretation": "Counterfactual Explanation",
    "explainMethod": "Explanation Methods",
    "viewScore": "View Score",
    "fetch": "Filter",
    "minConfidence": "Probability Threshold",
    "confidenceRange": "Probability and Range",
    "imgSort": "Sort Images By",
    "default": "Default",
    "byProbability": "Probabilities in descending order",
    "byUncertainty": "Uncertainties in descending order",
    "uncertainty": "uncertainty",
    "superposeImg": "Overlay on Original Image",
    "originalPicture": "Original Image",
    "forecastTag": "Prediction Tag",
    "forecastTagPosibility": "Prediction Tag (Probability)",
    "tag": "Tag",
    "filterImg": "Filter Image",
    "tagTip": "Query image data that contains any filter tag (Only tags with data are displayed)",
    "typeTip": "Query image data that contains any prediction type",
    "labelTip": "Only tags with data are displayed",
    "confidence": "Probability",
    "forecastTagTip": "When the inference image has the correct tag, the following three flags are displayed in the tag row",
    "TP": "TP, indicates true positive. For this tag (label), the sample is predicted to be positive, and is indeed positive;",
    "FN": "FN, indicates false negative. For this tag (label), the sample is predicted to be negative, but is positive in fact;",
    "FP": "FP, indicates false positive. For this tag (label), the sample is predicted to be positive, but is negative in fact;",
    "coverfactualInterpretation": "Mask-based Counterfactual Explanation",
    "viewExplanation": "View Explanation",
    "maskingProcess": "Layer-by-layer Masking Process",
    "mainTipTitle": "Function description:",
    "mainTipPartOne": "This function visualizes the basis for model classification. After the to-be-explained model, the image, and the tag are selected, a contribution degree of each pixel in the original image to the selected tag is calculated by using an explanation method, and visualization is performed by using a saliency map similar to a heatmap. A brighter color indicates that the corresponding area contributes more to the selected tag of the model prediction. The darker the color, the smaller the contribution of the area to the selected tag.",
    "mainTipPartTwo": "A saliency map helps you understand the features related to the specified tag during deep neural network inference. When the inference basis and expectation of a model are different, you can debug the model by referring to the saliency map so that the model can perform inference based on proper features.",
    "mainTipPartThree": "For details about how to generate saliency maps, see section 3.2 'Local Methods' in",
    "mainTipPartFour": "https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9050829",
    "noExplainer": "Select Explanation Method",
    "minConfidenceTip": "Probability threshold of a prediction tag. A tag is recorded as a prediction tag if its output probability is greater than the threshold.",
    "noData": "Loading data... Refresh the page later",
    "predictionType": "Prediction Type",
    "disableSaliencyMapTip": "No saliency map visualization log is available.",
    "disableHOCTip": "No counterfactual explanation log is available.",
    "hocMinConfidenceTip": "Display and explanation for tags whose prediction probability is greater than the prediction threshold",
    "imageList": "Image list",
    "dropEmptySwitch": "Hide",
    "dropEmptySwitchTip": "Hide data without interpretation results",
    "hocTitleTip": "Gradually shrink the display area to find the minimum display area where the prediction probability is greater than the threshold"
  },
  "metric": {
    "scoreSystem": "Scoring System",
    "comprehensive": "Comprehensive Assessment",
    "classify": "Classification Assessment",
    "singleMethod": "Single method and multiple indicators",
    "multiMethod": "Single indicator and multiple methods",
    "interpretation": "Explanation",
    "measurement": "Measurement",
    "disableMetricTip": "The result of this measurement method is irrelevant to the tag, the classification assessment result cannot be viewed.",
    "seeInterpretation": "You are viewing scores of the explanation method ",
    "seeMeasurement": "You are viewing scores of the measurement method ",
    "showGrade": " of different tag types",
    "evaluationScore": "Assessment Score",
    "weightAllocatgion": "Weight Configuration",
    "compositeScore": "Comprehensive Score",
    "metric": "Dimension",
    "inputWeightScore": "Enter a weight score between 0 and 1",
    "weightSumNotNull": "The sum of weights cannot be empty",
    "weightError": "Weight calculation error",
    "weightSum": "The sum of weights must be 1",
    "radarChart": "Explanation Method Comparison Radar Chart",
    "comprehensiveTooltip": "On the comprehensive assessment page, you can configure weights for different scoring dimensions to calculate the comprehensive scores of explanation methods to sort and filter the methods. Each explanation method has advantages in different scoring dimensions. You can refer to the description of each dimension and adjust weights based on the actual requirements to assess the explanation method. By default, the same weight is set for each dimension.",
    "classifyTooltip": "Classification assessment groups datasets by tag and measures the explanation methods based on data with different tags.",
    "scoreSystemtooltipOne": "Function description:",
    "scoreSystemtooltiptwo": "The scoring system provides multiple dimensions for scoring explanation methods.",
    "scoreSystemtooltipthree": "Scoring dimensions:",
    "scoreSystemtooltipfour": " - Faithfulness: evaluates the faithfulness of the explanation result to the model, that is, whether the saliency map correctly reflects the model classification basis. Modify the corresponding positions in the original image according to a certain rule (for example, from bright to dark) and transfer the modified image to the model for inference in sequence. If the brighter the area of the saliency map is, the greater the impact on the selected tag is, the higher the faithfulness of the interpretation result is. Conversely, the explanation result may not reflect the inference basis of the model. Currently, there are three mainstream solutions: naive faithfulness, insertion AUC, and deletion AUC.",
    "scoreSystemtooltipfive": "  - Localization: uses the bounding box of the dataset to assess the positioning accuracy of the highlighted area in the saliency map. Select an objective and related tag. If the explanation method accurately highlights the area related to the selected tag in the image, the highlighted area should overlap the bounding box of the selected objective. Localization assesses the location capability of the explanation result by assessing the overlapped area of the highlighted area and bounding box.",
    "scoreSystemtooltipsix": "- ClassSensitivity: evaluates the explanation through comparing saliency maps of max-confidence and min-confidence labels. Since models are expected to rely on different features for inference, an reason explainer should generate different saliecny map for different labels. The class sensitivity is evaluated through calculating the correlation between saliency maps of max-confidence and min-confidence labels.",
    "scoreSystemtooltipseven": "- Robustness: evaluate the stability of explainer, i.e., how much will the saliency map change if some noise is added to the original image. Disturb the original image by add little noise, which have     no effect on the inference. The less the saliency map changes, the more robust the explainer is.",
    "errorTipTitle": "Exception scenario：",
    "errorTipText": "if NaN is displayed, please check the runtime log."
  },
  "lossAnalysis": {
    "titleText": "Loss Function Multidimensional Analysis",
    "isopleth": "Isoline Map",
    "reliefMap": "Topographic Map",
    "threeDiagram": "3D Map",
    "mapColorSelection": "Color",
    "pathCurve": "Track Curve",
    "lineColor": "Color",
    "lineWidth": "Width",
    "setLineNum": "Contour Lines",
    "playTrackAnimation": "Play Track Animation",
    "restore": "Restore",
    "downloadPic": "Download",
    "fullScreen": "Full Screen",
    "fitScreen": "Fit to screen",
    "stepSelection": "Step Selection",
    "intervalRange": "Range",
    "visualSettings": "Visual Display Settings",
    "surfaceTransparency": "Transparency",
    "lightIntensity": "Illumination",
    "illuminationPoint": "Illumination Position",
    "alpha": "alpha",
    "beta": "beta",
    "distance": "distance",
    "cameraPosition": "Camera Position",
    "cameraRotationAngle": "Camera Rotation Angle",
    "basicTrainingInfo": "Basic Training Information",
    "network": "Network",
    "optimizer": "Optimizer",
    "learning_rate": "Learning Rate",
    "decomposition": "Dimension Reduction Mode",
    "ratio": "Sampling Point resolution",
    "unit": "Unit",
    "selectedInterval": "Selected Range",
    "step_per_epoch": "Step/Epoch",
    "lossValue": "loss value",
    "trainingStep": "training\nstep",
    "dataSelectTip": "Please select the graph to be compared on the right",
    "dataToolTip": "The line chart on the right side of this function is the actual training loss value curve, and the large image on the left side of the page is an approximate representation of the training loss surface. Due to the randomness of the data and other reasons, the specific value may not be exactly the same as the actual training loss value.",
    "basicTrainingTip": "If part of the basic training information is missing, please check whether the traceability data is collected correctly.",
    "graph3DOperateTip": "Press and hold the left button of the mouse to rotate the 3D image, and press and hold the middle button of the mouse to pan the 3D image"
  },
  "lossCompare": {
    "titleText": "Loss Graph Comparison",
    "visualiation": "Visualization",
    "compareMode": "Comparison mode",
    "tiled": "Tile",
    "superimposed": "Overlay",
    "colorMatching": "Color",
    "trainInfo": "Training Information",
    "evaluateInfo": "Evaluation Metrics",
    "conpoint": "Model Convergence Point",
    "accuracy": "Accuracy",
    "high": "High",
    "low": "Low",
    "diagram3DSVLimitTip": "A maximum of two graphs can be selected for comparison",
    "more": "View More",
    "trainingTip": "If some basic training information or evaluation indicators are missing, please check whether the traceability data is collected correctly."
  },
  "operatorPrecision": {
    "title": "Reduced Precision Operator Analysis",
    "placeTitle": "Please enter the operator name to be searched",
    "searchBtn": "search",
    "download": "download",
    "view": "check",
    "opName": "op_name",
    "fullName": "fillname_with_scope",
    "opType": "op_type",
    "precisionFlag": "up/down precision_flag",
    "isReduceOp": "is_reduce_op",
    "input": "Input",
    "output": "Output",
    "yes": "Yes",
    "no": "No"
  },
  "error": {
    "50540000": "System error.",
    "50540001": "Incorrect parameter type. Check whether the request parameter types meet the requirements.",
    "50540002": "Incorrect parameter value. Check whether the request parameter values meet the requirements.",
    "50540003": "Mandatory parameters are missing. Check whether all mandatory parameters meet the requirements.",
    "50545001": "The API route resource does not exist.",
    "50545002": "Incorrect HTTP method for requesting the API.",
    "50545005": "The training job does not exist.",
    "50545007": "Loading summary data... Please wait.",
    "50545009": "The queried node is not in the graph. Please refresh.",
    "5054500A": "Failed to decode the URL of the training job ID.",
    "5054500C": "The computational graph does not exist. Please refresh.",
    "5054500D": "The image data does not exist. Please refresh.",
    "5054500E": "The scalar data does not exist. Please refresh.",
    "5054500F": "The parameter distribution data does not exist. Please refresh.",
    "50545010": "The requested data is not in the cache. Refresh.",
    "50545017": "Collect summary data in the training script and save the Loss Multi graph data.",
    "50542082": "The model name is missing.",
    "50542085": "Invalid model name.",
    "50542215": "Incorrect query parameters.",
    "50542216": "The summary log file is not found.",
    "50542217": "Incorrect summary log path.",
    "50542218": "Incorrect filtering parameter.",
    "50545012": "The tensor data does not exist. Please refresh.",
    "50545013": "The requested data exceeds the upper limit 100,000. Shard or query other dimensions.",
    "50545014": "The queried tensor data has been replaced by new data. Please refresh.",
    "50545016": "The number of requested tensors exceeds 10 million and cannot be displayed.",
    "50546083": "The profiler directory does not exist.",
    "50546084": "Profiler job not exist.",
    "50546189": "This parallel mode is not supported. Support only data parallel, model parallel, pipeline parallel.",
    "5054618A": "Parallel strategy data provided has abnomaly.",
    "5054618B": "Parallel strategy data not exist. Check whether the parallel_strategy_<rank_id>.json file exists in the profiler directory.",
    "5054618C": "An error occurred parsing the parallel policy data file.",
    "50548001": "Ascend AI Processor information query timed out.",
    "5054B080": "Incorrect parameter type. Please check the input parameter type.",
    "5054B081": "Incorrect parameter value. Please check the input parameter.",
    "5054B180": "Failed to create the watchpoint. Please stop training and try again.",
    "5054B181": "Failed to update the watchpoint. Please stop training and try again.",
    "5054B182": "Failed to delete the watchpoint. Please stop training and try again.",
    "5054B183": "Backend training is in progress or has ended. Please try again later",
    "5054B184": "The operation is too fast, the backend service has been suspended.",
    "5054B189": "Do not set the value repeatedly.",
    "5054B083": "Failed to create the watchpoint. Do not use invalid rules.",
    "5054B202": "The debugger offline server module is not found",
    "5054B203": "Failed to the Ascend toolkit package, please install it and set `ASCEND_TOOLKIT_PATH` in the environment correstly.",
    "5054B283": "A tensor is being downloaded. Please try again later.",
    "5054B286": "The .dump_metadata/data_dump.json file in the summary directory is missing or damaged. Please check the integrity of the dump data in the directory.",
    "5054000C": "Insufficient memory, please try again after freeing memory."
  }
}
